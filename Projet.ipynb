{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from impyute.imputation.cs import mice#\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer#\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import missingno as msno#\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from missingpy import KNNImputer\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option(\"display.max_rows\", 8)\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "from missingpy import MissForest\n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn import decomposition\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On utilisera une méthode d'imputation multiple qui gère différentes types de variables\n",
    "le but étant que les variables gardent la même distribution qu'auparavant\n",
    "On se doit tout de même spécifier le type des variables\n",
    "\n",
    "web:https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>530101</td>\n",
       "      <td>38.50</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>45.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>534817</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>530334</td>\n",
       "      <td>38.30</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5290409</td>\n",
       "      <td>39.10</td>\n",
       "      <td>164</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.00</td>\n",
       "      <td>7.20</td>\n",
       "      <td>3</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>527702</td>\n",
       "      <td>37.20</td>\n",
       "      <td>72</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>529386</td>\n",
       "      <td>37.50</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>60.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>530612</td>\n",
       "      <td>36.50</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>534618</td>\n",
       "      <td>37.2</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V0  V1       V2     V3   V4  V5   V6   V7   V8   V9  ...  V13  V14   V15  \\\n",
       "0    2   1   530101  38.50   66  28    3    3  NaN    2  ...  NaN  NaN   NaN   \n",
       "1    1   1   534817   39.2   88  20  NaN  NaN    4    1  ...  NaN  NaN   NaN   \n",
       "2    2   1   530334  38.30   40  24    1    1    3    1  ...  NaN  NaN   NaN   \n",
       "3    1   9  5290409  39.10  164  84    4    1    6    2  ...    1    2  5.00   \n",
       "..  ..  ..      ...    ...  ...  ..  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "296  2   1   527702  37.20   72  24    3    2    4    2  ...    3    1   NaN   \n",
       "297  1   1   529386  37.50   72  30    4    3    4    1  ...    2    1   NaN   \n",
       "298  1   1   530612  36.50  100  24    3    3    3    1  ...    3    1   NaN   \n",
       "299  1   1   534618   37.2   40  20  NaN  NaN  NaN  NaN  ...  NaN  NaN   NaN   \n",
       "\n",
       "    V16  V17    V18   V19  V20   V21 V23  \n",
       "0     3    5  45.00  8.40  NaN   NaN   2  \n",
       "1     4    2     50    85    2     2   2  \n",
       "2     1    1  33.00  6.70  NaN   NaN   2  \n",
       "3     3  NaN  48.00  7.20    3  5.30   1  \n",
       "..   ..  ...    ...   ...  ...   ...  ..  \n",
       "296   4    4  44.00   NaN    3  3.30   1  \n",
       "297   3    5  60.00  6.80  NaN   NaN   1  \n",
       "298   4    4  50.00  6.00    3  3.40   1  \n",
       "299   4    1     36    62    1     1   2  \n",
       "\n",
       "[300 rows x 23 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dapp = pd.read_csv(\"horse-colic.data\" , sep = \"\\s+\", names = [\"V\"+str(i) for i in range(28)])\n",
    "Dtest = pd.read_csv(\"horse-colic.test\" , sep = \"\\s+\", names = [\"V\"+str(i) for i in range(28)])\n",
    "liste_drop = [\"V22\",\"V24\",\"V25\",\"V26\",\"V27\"]\n",
    "Dapp = Dapp.drop(liste_drop , axis = 1)\n",
    "Dtest = Dtest.drop(liste_drop , axis = 1)\n",
    "Dapp = Dapp.replace(\"?\",np.nan)\n",
    "Dtest = Dtest.replace(\"?\",np.nan)\n",
    "Dtest\n",
    "Dapp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Noms de variables qualitatives et quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V3', 'V4', 'V5', 'V15', 'V18', 'V19', 'V21']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "liste_categorical = [] ; liste_numerical = []\n",
    "for i in range(24):\n",
    "    if(i in list(range(3)) + list(range(6 , 15)) + [16 , 17 , 20 , 23]):\n",
    "        d[\"V\"+str(i)] = \"category\"\n",
    "        liste_categorical.append(\"V\"+str(i))\n",
    "    elif(i != 22):\n",
    "        d[\"V\"+str(i)] = \"float64\"\n",
    "        liste_numerical.append(\"V\"+str(i))\n",
    "liste_categorical\n",
    "liste_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V0': 'category',\n",
       " 'V1': 'category',\n",
       " 'V2': 'category',\n",
       " 'V3': 'float64',\n",
       " 'V4': 'float64',\n",
       " 'V5': 'float64',\n",
       " 'V6': 'category',\n",
       " 'V7': 'category',\n",
       " 'V8': 'category',\n",
       " 'V9': 'category',\n",
       " 'V10': 'category',\n",
       " 'V11': 'category',\n",
       " 'V12': 'category',\n",
       " 'V13': 'category',\n",
       " 'V14': 'category',\n",
       " 'V15': 'float64',\n",
       " 'V16': 'category',\n",
       " 'V17': 'category',\n",
       " 'V18': 'float64',\n",
       " 'V19': 'float64',\n",
       " 'V20': 'category',\n",
       " 'V21': 'float64',\n",
       " 'V23': 'category'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Affectation des \"bons\" types pour chaque variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "Dapp = Dapp.astype(d)\n",
    "Dtest = Dtest.astype(d)\n",
    "Dapp_num = Dapp.select_dtypes(include=['float64']) ; Dapp_cat = Dapp.select_dtypes(include=['category'])\n",
    "Dtest_num = Dtest.select_dtypes(include=['float64']) ; Dtest_cat = Dtest.select_dtypes(include=['category'])\n",
    "Dtest_cat.loc[: , \"V9\"] = pd.Series(pd.Categorical(Dtest_cat.loc[: , \"V9\"], categories=[\"1\",\"2\",\"3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation multiple sur les variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(l): \n",
    "    return np.array([float(x) for x in l])\n",
    "\n",
    "imputed_training=mice(np.array(list(map(g , Dapp_num.values))))\n",
    "imputed_test = mice(np.array(list(map(g , Dtest_num.values))))\n",
    "\n",
    "Dapp_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputed_training))))).round(2)\n",
    "Dapp_num_imputed.columns = liste_numerical\n",
    "\n",
    "Dtest_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputed_test))))).round(2)\n",
    "Dtest_num_imputed.columns = liste_numerical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On a généré quelques valeurs négatives, il est nécessaire d'effectuer de nouvelles imputations sur nos données\n",
    "on utilisera des imputations simples de type KNN basées sur la notion de distance\n",
    "on ne peut pas se permettre de prendre des poids uniformes, \n",
    "en effet, il se peut que le 2e plus proche soit en réalité très loin du point par rapport au premier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dapp_num_imputed[Dapp_num_imputed < 0] = np.nan\n",
    "Dtest_num_imputed[Dtest_num_imputed < 0] = np.nan\n",
    "\n",
    "distances_app = pdist(Dapp_num_imputed.values, metric='euclidean')\n",
    "dist_matrix_app = squareform(distances_app)\n",
    "matrice_distance_app = pd.DataFrame(list(map(np.ravel, (list(dist_matrix_app))))).round(2)\n",
    "\n",
    "distances_test = pdist(Dtest_num_imputed.values, metric='euclidean')\n",
    "dist_matrix_test = squareform(distances_test)\n",
    "matrice_distance_test = pd.DataFrame(list(map(np.ravel, (list(dist_matrix_test))))).round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Le choix du nombre de voisins est difficile, on fait donc des choix arbitraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=15, weights=\"distance\")\n",
    "Dapp_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputer.fit_transform(Dapp_num_imputed)))))).round(2)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3, weights=\"distance\")\n",
    "Dtest_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputer.fit_transform(Dtest_num_imputed)))))).round(2)\n",
    "\n",
    "Dapp_num_imputed.columns = liste_numerical ; Dtest_num_imputed.columns = liste_numerical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Calcul de la proportion de données manquantes pour chaque variable numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V3': 0.13235294117647056,\n",
       " 'V4': 0.02941176470588236,\n",
       " 'V5': 0.19117647058823528,\n",
       " 'V15': 0.7647058823529411,\n",
       " 'V18': 0.11764705882352944,\n",
       " 'V19': 0.1470588235294118,\n",
       " 'V21': 0.5441176470588236}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{lab : 1-(len(Dtest_num[lab].dropna())/len(Dtest_num)) for lab in liste_numerical} \n",
    "#les proportions de données manquantes pour chaque variable numérique sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V3': 0.19999999999999996,\n",
       " 'V4': 0.07999999999999996,\n",
       " 'V5': 0.19333333333333336,\n",
       " 'V15': 0.8233333333333334,\n",
       " 'V18': 0.09666666666666668,\n",
       " 'V19': 0.10999999999999999,\n",
       " 'V21': 0.6599999999999999}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{lab : 1-(len(Dapp_num[lab].dropna())/len(Dapp_num)) for lab in liste_numerical}\n",
    "#les proportions de données manquantes pour chaque variable numérique sur les données d'apprentissage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "L'objectif est de comparer les distributions pour voir si l'on observe une certaine cohérence après imputation\n",
    "on compare les distributions avant/après\n",
    "on calcule aussi la proportion de données manquantes pour être sûr que la comparaison ait un sens.\n",
    "il faut que le % de données manquantes ne soit ni trop faible ni trop élevé pour pouvoir comparer\n",
    "on peut faire une \"évaluation\" visuelle de notre imputation sur la variable choisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 544
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = Dapp_num.V21\n",
    "y = Dapp_num_imputed.V21\n",
    "plt.hist([x, y], label=['Missing data', 'Imputed data'] , color = [\"plum\",\"peru\"])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation multiple des variables qualitatives"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "La variable ID hôpital sera supprimée, qui peut être considéré (globalement) comme un identifiant pour les chevaux\n",
    "en effet, si l'on conserve cette variable en termes d'ajustement, on sera performant.\n",
    "cependant, nos algorithmes de prédiction ne seront pas bons d'un point de vue de la généralisation\n",
    "\n",
    "\n",
    "62 lignes des données de test sont des nouveaux identifiants -- > overfitting\n",
    "On peut regarder ce qu'il peut se passer si on décide de la conserver dans la page html Overfitting.html\n",
    "\n",
    "\n",
    "Réf : Unleash Machine Learning Techniques, De Raghav Bali, Dipanjan Sarkar, Brett Lantz p.393\n",
    "Advances in Computing and Information Technology, Natarajan Meghanathan, Dhinaharan Nagamalai, Nabendu Chaki P.352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n"
     ]
    }
   ],
   "source": [
    "Dapp_cat = Dapp_cat.drop([\"V2\"] , axis = 1) ; Dtest_cat = Dtest_cat.drop([\"V2\"] , axis = 1)\n",
    "cat_cols = [Dapp_cat.columns.get_loc(col) for col in Dapp_cat.select_dtypes(['category']).columns.tolist()]\n",
    "\n",
    "imputer = MissForest(random_state = 100) ## imputation pour les variables qualitatives à l'aide de fôrets aléatoires\n",
    "\n",
    "Dapp_cat_imputed = imputer.fit_transform(Dapp_cat , cat_vars = cat_cols)\n",
    "Dapp_cat_imputed = pd.DataFrame(list(map(np.ravel, (list(Dapp_cat_imputed)))))\n",
    "Dapp_cat_imputed.columns = [x for x in liste_categorical if(x!=\"V2\")] #if(x!=\"V2\")\n",
    "Dapp_cat_imputed = Dapp_cat_imputed.apply(lambda x : x.astype(int).astype(str).astype(\"category\") , axis = 1)\n",
    "\n",
    "Dtest_cat_imputed = imputer.transform(Dtest_cat)\n",
    "Dtest_cat_imputed = pd.DataFrame(list(map(np.ravel, (list(Dtest_cat_imputed)))))\n",
    "Dtest_cat_imputed.columns = [x for x in liste_categorical if(x!=\"V2\")] #if(x!=\"V2\")\n",
    "Dtest_cat_imputed = Dtest_cat_imputed.apply(lambda x : x.astype(int).astype(str).astype(\"category\") , axis = 1)\n",
    "Dtest_cat_imputed.loc[: , \"V9\"] = pd.Series(pd.Categorical(Dtest_cat_imputed.loc[: , \"V9\"], categories=[\"1\",\"2\",\"3\"]))\n",
    "#une modalité de V9 n'est pas présente dans la variable V9 des données de test : il faut rajouter une catégorie\n",
    "#pour la variable V9 des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V0': 0.014705882352941124,\n",
       " 'V1': 0.0,\n",
       " 'V6': 0.13235294117647056,\n",
       " 'V7': 0.20588235294117652,\n",
       " 'V8': 0.014705882352941124,\n",
       " 'V9': 0.08823529411764708,\n",
       " 'V10': 0.11764705882352944,\n",
       " 'V11': 0.11764705882352944,\n",
       " 'V12': 0.13235294117647056,\n",
       " 'V13': 0.3970588235294118,\n",
       " 'V14': 0.3970588235294118,\n",
       " 'V16': 0.38235294117647056,\n",
       " 'V17': 0.36764705882352944,\n",
       " 'V20': 0.42647058823529416,\n",
       " 'V23': 0.0}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{lab : 1-(len(Dtest_cat[lab].dropna())/len(Dtest)) for lab in liste_categorical if(lab != \"V2\")} \n",
    "#les proportions de données manquantes pour chaque variable qualitative sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V0': 0.0033333333333332993,\n",
       " 'V1': 0.0,\n",
       " 'V6': 0.18666666666666665,\n",
       " 'V7': 0.22999999999999998,\n",
       " 'V8': 0.15666666666666662,\n",
       " 'V9': 0.10666666666666669,\n",
       " 'V10': 0.18333333333333335,\n",
       " 'V11': 0.1466666666666666,\n",
       " 'V12': 0.18666666666666665,\n",
       " 'V13': 0.3466666666666667,\n",
       " 'V14': 0.3533333333333334,\n",
       " 'V16': 0.33999999999999997,\n",
       " 'V17': 0.3933333333333333,\n",
       " 'V20': 0.55,\n",
       " 'V23': 0.0}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{lab : 1-(len(Dapp_cat[lab].dropna())/len(Dapp)) for lab in liste_categorical if(lab != \"V2\")}\n",
    "#les proportions de données manquantes pour chaque variable qualitative sur les données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1247ab088>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 359,
       "width": 544
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dapp_cat_imputed.V23.value_counts().sort_index().plot(kind = \"bar\")\n",
    "#en pratique, il est nécessaire de vérifier la distribution des variables avant\\après imputation\n",
    "#on trace donc des barplot pour avoir une idée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1245fac08>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 359,
       "width": 544
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dapp_cat[\"V23\"].value_counts().sort_index().plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouveau jeu de données imputé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.6</td>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.44</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.81</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V0 V1    V3    V4    V5 V6 V7 V8 V9 V10  ... V13 V14   V15 V16  V17   V18  \\\n",
       "0   2  1  38.5  54.0  20.0  3  1  2  2   3  ...   2   2  5.90   4    2  42.0   \n",
       "1   2  1  37.6  48.0  36.0  1  1  1  1   1  ...   2   1  5.52   1    3  44.0   \n",
       "2   1  1  37.7  44.0  28.0  3  4  3  2   5  ...   1   1  2.76   3    5  45.0   \n",
       "3   1  1  37.0  56.0  24.0  3  1  4  2   4  ...   1   1  1.44   4    5  35.0   \n",
       ".. .. ..   ...   ...   ... .. .. .. ..  ..  ...  ..  ..   ...  ..  ...   ...   \n",
       "64  2  1  37.8  42.0  40.0  1  1  1  1   1  ...   2   1  7.81   3    3  36.0   \n",
       "65  1  1  38.0  60.0  12.0  1  1  2  1   2  ...   1   1  1.97   1    4  44.0   \n",
       "66  2  1  38.0  42.0  12.0  3  3  3  1   1  ...   2   1  6.10   4    1  37.0   \n",
       "67  2  1  37.6  88.0  36.0  3  1  1  1   3  ...   1   3  1.50   4    4  44.0   \n",
       "\n",
       "     V19  V20   V21 V23  \n",
       "0    6.3    2  4.92   2  \n",
       "1    6.3    1  5.00   2  \n",
       "2   70.0    3  2.00   1  \n",
       "3   61.0    3  2.00   2  \n",
       "..   ...  ...   ...  ..  \n",
       "64   6.2    1  3.09   2  \n",
       "65  65.0    3  2.00   1  \n",
       "66   5.8    2  3.10   2  \n",
       "67   6.0    2  8.88   1  \n",
       "\n",
       "[68 rows x 22 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dapp_imputed = pd.concat([Dapp_num_imputed.reset_index(drop=True), Dapp_cat_imputed], axis=1)\n",
    "Dapp_imputed.columns = [int(x[1:]) for x in Dapp_imputed.columns]\n",
    "Dapp_imputed = Dapp_imputed.sort_index(axis = 1)\n",
    "Dapp_imputed.columns = [\"V\"+str(x) for x in Dapp_imputed.columns]\n",
    "\n",
    "Dtest_imputed = pd.concat([Dtest_num_imputed.reset_index(drop=True), Dtest_cat_imputed], axis=1)\n",
    "Dtest_imputed.columns = [int(x[1:]) for x in Dtest_imputed.columns]\n",
    "Dtest_imputed = Dtest_imputed.sort_index(axis = 1)\n",
    "Dtest_imputed.columns = [\"V\"+str(x) for x in Dtest_imputed.columns]\n",
    "Dtest_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>1</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>39.1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>3</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>22.44</td>\n",
       "      <td>3</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>3</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.26</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V0 V1    V3     V4    V5 V6 V7 V8 V9 V10  ... V13 V14   V15 V16  V17  \\\n",
       "0    2  1  38.5   66.0  28.0  3  3  4  2   5  ...   1   1  5.75   3    5   \n",
       "1    1  1  39.2   88.0  20.0  3  3  4  1   3  ...   2   1  1.56   4    2   \n",
       "2    2  1  38.3   40.0  24.0  1  1  3  1   3  ...   1   1  6.02   1    1   \n",
       "3    1  9  39.1  164.0  84.0  4  1  6  2   2  ...   1   2  5.00   3    5   \n",
       "..  .. ..   ...    ...   ... .. .. .. ..  ..  ...  ..  ..   ...  ..  ...   \n",
       "296  2  1  37.2   72.0  24.0  3  2  4  2   4  ...   3   1  4.13   4    4   \n",
       "297  1  1  37.5   72.0  30.0  4  3  4  1   4  ...   2   1  5.89   3    5   \n",
       "298  1  1  36.5  100.0  24.0  3  3  3  1   3  ...   3   1  3.26   4    4   \n",
       "299  1  1  37.2   40.0  20.0  1  1  1  1   3  ...   2   1  1.98   4    1   \n",
       "\n",
       "      V18    V19  V20   V21 V23  \n",
       "0    45.0   8.40    2  3.57   2  \n",
       "1    50.0  85.00    2  2.00   2  \n",
       "2    33.0   6.70    1  3.26   2  \n",
       "3    48.0   7.20    3  5.30   1  \n",
       "..    ...    ...  ...   ...  ..  \n",
       "296  44.0  22.44    3  3.30   1  \n",
       "297  60.0   6.80    3  3.89   1  \n",
       "298  50.0   6.00    3  3.40   1  \n",
       "299  36.0  62.00    1  1.00   2  \n",
       "\n",
       "[300 rows x 22 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dapp_imputed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n'exécutez pas la cellule suivante: l'idée était de présenter notre démarche\n",
    "Pour la partie modèlisation/performance, on va se baser sur un autre jeu de données provenant de pickle.\n",
    "--> Il y a de l'aléa dans les imputations multiples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dtest_imputed.to_pickle(\"Dtest_imputed.pkl\") \n",
    "#Dapp_imputed.to_pickle(\"Dapp_imputed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation Pickle des données d'entraînement/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dapp_imputed = pd.read_pickle(\"Dapp_imputed.pkl\")\n",
    "Dtest_imputed = pd.read_pickle(\"Dtest_imputed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing sur le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_cat_bis = [x for x in liste_categorical if(x not in [\"V23\" , \"V2\"] )]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Au-delà du scaling que l'on fera pour chaque algorithme,\n",
    "\n",
    "Pour la régression logistique, on décide de supprimer la 1ère modalité de chaque variable qualitative, on évite avec celala  multicolinéarité qui est problématique dans le cadre d'une régression logistique.\n",
    "\n",
    "Pour les autres méthodes, on décide de conserver toutes les variables dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(name , Dapp_imputed , Dtest_imputed):\n",
    "    Dapp_imputed_bis = copy.deepcopy(Dapp_imputed) ; Dtest_imputed_bis = copy.deepcopy(Dtest_imputed)\n",
    "    scaler = MinMaxScaler()\n",
    "    Dapp_imputed_bis[liste_numerical] = scaler.fit_transform(Dapp_imputed_bis[liste_numerical])\n",
    "    Dapp_imputed_bis[\"V23\"] = pd.Series([1 if(x==\"1\") else 0 for x in Dapp_imputed_bis[\"V23\"]])\n",
    "    Dapp_imputed_bis = Dapp_imputed_bis.astype({\"V23\" : \"int32\"})\n",
    "    \n",
    "    Dtest_imputed_bis[liste_numerical] = scaler.transform(Dtest_imputed_bis[liste_numerical])\n",
    "    Dtest_imputed_bis[\"V23\"] = pd.Series([1 if(x==\"1\") else 0 for x in Dtest_imputed_bis[\"V23\"]])\n",
    "    Dtest_imputed = Dtest_imputed.astype({\"V23\" : \"int32\"})\n",
    "    if(name == \"logreg\"):\n",
    "        Dapp_imputed_bis = pd.get_dummies(Dapp_imputed_bis , columns = liste_cat_bis , drop_first = True)\n",
    "        Dtest_imputed_bis = pd.get_dummies(Dtest_imputed_bis , columns = liste_cat_bis , drop_first = True)\n",
    "    else:\n",
    "        Dapp_imputed_bis = pd.get_dummies(Dapp_imputed_bis , columns = liste_cat_bis)\n",
    "        Dtest_imputed_bis = pd.get_dummies(Dtest_imputed_bis , columns = liste_cat_bis)\n",
    "        \n",
    "    X_train = Dapp_imputed_bis.drop([\"V23\"] , axis = 1) ; Y_train = Dapp_imputed_bis[\"V23\"]\n",
    "    X_test = Dtest_imputed_bis.drop([\"V23\"] , axis = 1) ; Y_test = Dtest_imputed_bis[\"V23\"]\n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données d'entraînement/test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "En pratique, pour calibrer les paramètres de chaque méthode, on devrait utiliser une validation croisée LOOCV\n",
    "car notre jeu de données est relativement petit\n",
    "cependant cela est coûteux en termes de temps, on fera donc pour certaines méthode des validations croisées 3-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , Y_train , X_test , Y_test = generate_data(\"logreg\" , Dapp_imputed , Dtest_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941176470588235"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty = \"none\", solver = \"newton-cg\" , max_iter = 5000 , tol = 1e-6)\n",
    "logreg.fit(X_train , Y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_fit = logreg.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9033333333333333"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Il faut se garantir que nous ne sommes pas dans le cas de sur-apprentissage, on décide donc d'opter\n",
    "pour une régression logistique pénalisée dont la constante de pénalité sera déterminée par validation croisée LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_selection_log(X, y,Cs):\n",
    "    logreg = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\" , max_iter = 5000 , tol = 1e-6)\n",
    "    parameters = {'C':Cs}\n",
    "    clf = GridSearchCV(logreg, parameters, cv = KFold(n_splits = 300))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8676470588235294"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "C_log = param_selection_log(X_train, Y_train , [.001 , 0.01 , 0.1 , 1 , 10 , 100])[\"C\"]\n",
    "logreg = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\" , max_iter = 5000 , tol = 1e-6 , C = C_log)\n",
    "logreg.fit(X_train , Y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_fit = logreg.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8633333333333333"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On constate que l'écart est moindre entre l'erreur de prédiction et d'apprentissage !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"reg_log\" , accuracy_score(y_fit, Y_train) , accuracy_score(y_pred, Y_test) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , Y_train , X_test , Y_test = generate_data(\"no_reg\" , Dapp_imputed , Dtest_imputed)\n",
    "Y_train = pd.Series([-1 if(y==0) else 1 for y in Y_train])\n",
    "Y_test = pd.Series([-1 if(y==0) else 1 for y in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cette méthode est coûteuse, on opte pour une validation 3-fold\n",
    "def svc_param_selection_lin(X, y,Cs):\n",
    "    parameters = {'kernel':['linear'], 'C':Cs}\n",
    "    svc = svm.SVC(gamma = 1 , coef0 = 0)\n",
    "    clf = GridSearchCV(svc, parameters , return_train_score = True , cv = KFold(n_splits = 3))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 664 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "C_lin = svc_param_selection_lin(X_train, Y_train , [0.01 , 0.1 , 1 , 10 , 100])[\"C\"]\n",
    "clf = LinearSVC(C = C_lin , max_iter = 100000)\n",
    "clf.fit(X_train , Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_fit = clf.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Même en augmentant la constante de tolérance on arrive pas à obtenir la nullité de l'erreur d'ajustement\n",
    "cela implique qu'il y a de fortes chances que les données soient non-séparables linéairement\n",
    "\n",
    "Naturellement, on se dirigera vers les SVM à noyaux de manière à déterminer un hyperplan dans un espace \n",
    "de plus grande dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"svm_lin\" , accuracy_score(y_fit, Y_train) ,accuracy_score(y_pred, Y_test) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM polynomiale"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 minute, on utilise lorsque c'est possible LOOCV, en général on obtiendra un degré égal à 2\n",
    "\n",
    "les résultats sont nettement différents selon la méhtode de VC : pour une 3-fold, on obtiendra un degré égal  à 1\n",
    "soit une SVM linéaire ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def svc_param_selection_poly(X, y,Cs , degree):\n",
    "    parameters = {'kernel':['poly'], 'C':Cs , \"degree\" : degree}\n",
    "    svc = svm.SVC(gamma = 1)\n",
    "    clf = GridSearchCV(svc, parameters , return_train_score = True , cv = KFold(n_splits = 300))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params_poly = svc_param_selection_poly(X_train, Y_train , [0.0001,0.001 ,0.01 , 0.1 , 1] , list(range(1,3)))\n",
    "ksvm_poly = svm.SVC(kernel=\"poly\", degree = params_poly[\"degree\"] , C = params_poly[\"C\"] , gamma = 1)               \n",
    "ksvm_poly.fit(X_train, Y_train)\n",
    "y_pred = ksvm_poly.predict(X_test)\n",
    "y_fit = ksvm_poly.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n",
    "## on décide de ne pas optimiser la constante du polynôme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'degree': 2, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On constate donc que ce modèle n'est pas utilisable dans le cadre de notre problèmatique car il y a des chances que la variance soit élevée pour cet algorithme malgré notre validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"svm_poly\" , accuracy_score(y_fit, Y_train) ,accuracy_score(y_pred, Y_test) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y,Cs,Gs): #on se limite à une VC 3-fold car moins coûteuse\n",
    "    parameters = {'C': Cs, 'gamma': Gs, 'kernel': ['rbf']}\n",
    "    svc = svm.SVC()\n",
    "    clf = GridSearchCV(svc, parameters , return_train_score = True , cv = KFold(n_splits = 3))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = svc_param_selection(X_train, Y_train , [10 , 20 , 30 , 40 , 50] , [0.0001 , 0.001 , 0.1 , 1])\n",
    "\n",
    "ksvm = svm.SVC(kernel=\"rbf\", gamma = params[\"gamma\"] , C = params[\"C\"])               \n",
    "ksvm.fit(X_train, Y_train)\n",
    "y_pred = ksvm.predict(X_test)\n",
    "y_fit = ksvm.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n",
    "#le calibrage  de gamma peut s'avérer très compliqué, il en est de même pour le choix du noyau ainsi que de la tolérance,\n",
    "#on voit aussi que les performances sur les données de test sont moins bonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 40, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966666666666667"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cet algorithme semble avoir une variance forte malgré la VC, cela peut être due à notre calibrage ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"svm_rbf\" , accuracy_score(y_fit, Y_train) , accuracy_score(y_pred, Y_test) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Essayons de déterminer le paramètre de complexité m avec l'erreur OOB.\n",
    "Deux hyper-paramètres devront êtres calibrés : max_features (nombre de variable à choisir pendant chaque coupure) et la profondeur des arbres\n",
    "\n",
    "En effet, si min_samples_split est est faible alors la variance des arbres est forte --> la fôret aura une forte variance\n",
    "quelque soit la valeur de max_features.\n",
    "\n",
    "On doit aussi calibrer ce paramètre sinon on aura un problème de sur-apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_m(liste):\n",
    "    l = []\n",
    "    for m in liste:\n",
    "        clf = RandomForestClassifier(random_state = 0,\n",
    "                             n_estimators = 200 , max_features = m , min_samples_split = 2,\n",
    "                            oob_score = True)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        l.append((m , clf.oob_score_))\n",
    "    return min(l , key = lambda x : x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8088235294117647"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "m = oob_m(range(1,8))\n",
    "clf = RandomForestClassifier(random_state = 0,\n",
    "                             n_estimators = 100 , max_features = m , min_samples_split = 2,\n",
    "                            oob_score = True)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_fit = clf.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dans notre cas de figure, déterminer m à l'aide de l'erreur OOB semble être une source de sur-apprentissage\n",
    "on optera pour une validation croisée pour déterminer m\n",
    "\n",
    "l'erreur d'apprentissage est nulle, on pourrait penser que cet algorithme admette une variance forte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_CV(ms):\n",
    "    rfc = RandomForestClassifier(random_state = 0, min_samples_split = 2, n_estimators = 100)\n",
    "    param_grid = {'max_features': ms}\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= KFold(n_splits = 3))\n",
    "    CV_rfc.fit(X_train, Y_train)\n",
    "    return CV_rfc.best_params_[\"max_features\"]\n",
    "#on décide de faire une 3-fold car la LOO est coûteuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8088235294117647"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ms = list(range(1,6))\n",
    "m = rfc_CV(ms)\n",
    "rfc = RandomForestClassifier(random_state = 0,\n",
    "                             n_estimators = 100 , max_features = m , min_samples_split = 2,\n",
    "                            oob_score = True)\n",
    "rfc.fit(X_train, Y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_fit = rfc.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "il semblerait que les arbres profonds ont une forte variance\n",
    "\n",
    "l'overfitting, provient de la profondeur des arbres, on veut qu'il soit profond car des arbres profonds ont un biais faible, c'est l'un des principes des fôrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"Rf\" , accuracy_score(y_fit, Y_train) , accuracy_score(y_pred, Y_test) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_CV(ks):\n",
    "    neigh = KNeighborsClassifier()\n",
    "    param_grid = {'n_neighbors': ks}\n",
    "    CV_knn = GridSearchCV(estimator=neigh, param_grid=param_grid, cv= KFold(n_splits = 3))\n",
    "    CV_knn.fit(X_train, Y_train)\n",
    "    return CV_knn.best_params_[\"n_neighbors\"]\n",
    "## avec LOOCV , k = 5 --> accuracy_train = 0.89 = 40 secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 861 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "k = knn_CV(list(range(2,20)))\n",
    "neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh.fit(X_train, Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "y_fit = neigh.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit , Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"knn\" , accuracy_score(y_fit , Y_train) , accuracy_score(y_pred, Y_test)])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Essayons de réduire la dimension avant d'effectuer une KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "pipe = Pipeline(steps=[('pca', pca), ('knn', knn)])\n",
    "n_components = [6, 8, 10]\n",
    "params_grid = [{\n",
    "'knn__n_neighbors': list(range(1,11)),\n",
    "'pca__n_components': n_components,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941176470588235"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd = GridSearchCV(pipe, param_grid = params_grid , cv = KFold(n_splits = 3))\n",
    "grd.fit(X_train , Y_train)\n",
    "accuracy_score(grd.predict(X_test) , Y_test)\n",
    "## la performance reste faible malgré la réduction de la dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 7, 'pca__n_components': 6}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_train , grd.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_CV(ns ,ls):\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1) , random_state=0)\n",
    "    param_grid = {'n_estimators': ns , \"learning_rate\" : ls}\n",
    "    CV_ada = GridSearchCV(estimator=ada, param_grid=param_grid, cv= KFold(n_splits = 3))\n",
    "    CV_ada.fit(X_train, Y_train)\n",
    "    return CV_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = ada_CV(list(range(14,25)) , np.linspace(0.15 , 0.5 , 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5, 'n_estimators': 22}"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators = params[\"n_estimators\"] ,\n",
    "                         learning_rate = params[\"learning_rate\"],\n",
    "                         random_state=0)\n",
    "ada.fit(X_train, Y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "y_fit = ada.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833333333333333"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accuracy_score(y_fit, Y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"ada\" , accuracy_score(y_fit, Y_train) , accuracy_score(y_pred, Y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_grid_search(X,y,depth):\n",
    "    param_grid = {'max_depth': depth}\n",
    "    dtree_model=DecisionTreeClassifier(random_state = 0)\n",
    "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv= KFold(n_splits = 3))\n",
    "    dtree_gscv.fit(X, y)\n",
    "    return dtree_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = dtree_grid_search(X_train,Y_train,list(range(3,20)))[\"max_depth\"]\n",
    "arb = DecisionTreeClassifier(random_state=0 , max_depth = P)\n",
    "arb.fit(X_train, Y_train)\n",
    "y_pred = arb.predict(X_test)\n",
    "y_fit = arb.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train) #cet algorithme semble admettre une forte variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice.append([\"tree\" , accuracy_score(y_fit, Y_train) , accuracy_score(y_pred, Y_test) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['reg_log', 0.8633333333333333, 0.8676470588235294],\n",
       " ['svm_lin', 0.87, 0.8235294117647058],\n",
       " ['svm_poly', 0.9466666666666667, 0.7647058823529411],\n",
       " ['svm_rbf', 0.9966666666666667, 0.7647058823529411],\n",
       " ['knn', 0.93, 0.7647058823529411],\n",
       " ['tree', 0.92, 0.8235294117647058]]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
