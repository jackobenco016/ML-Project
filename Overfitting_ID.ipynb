{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "from impyute.imputation.cs import mice#\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer#\n",
    "import missingno as msno#\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from missingpy import KNNImputer\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option(\"display.max_rows\", 8)\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "from missingpy import MissForest\n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn import decomposition\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dapp = pd.read_csv(\"horse-colic.data\" , sep = \"\\s+\", names = [\"V\"+str(i) for i in range(28)])\n",
    "Dtest = pd.read_csv(\"horse-colic.test\" , sep = \"\\s+\", names = [\"V\"+str(i) for i in range(28)])\n",
    "liste_drop = [\"V22\",\"V24\",\"V25\",\"V26\",\"V27\"]\n",
    "Dapp = Dapp.drop(liste_drop , axis = 1)\n",
    "Dtest = Dtest.drop(liste_drop , axis = 1)\n",
    "Dapp = Dapp.replace(\"?\",np.nan)\n",
    "Dtest = Dtest.replace(\"?\",np.nan)\n",
    "#Dtest\n",
    "#Dapp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V3', 'V4', 'V5', 'V15', 'V18', 'V19', 'V21']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "liste_categorical = [] ; liste_numerical = []\n",
    "for i in range(24):\n",
    "    if(i in list(range(3)) + list(range(6 , 15)) + [16 , 17 , 20 , 23]):\n",
    "        d[\"V\"+str(i)] = \"category\"\n",
    "        liste_categorical.append(\"V\"+str(i))\n",
    "    elif(i != 22):\n",
    "        d[\"V\"+str(i)] = \"float64\"\n",
    "        liste_numerical.append(\"V\"+str(i))\n",
    "liste_categorical\n",
    "liste_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_V2 = list(set(list(Dapp.V2.unique()) + list(Dtest.V2.unique()) ))\n",
    "label_V2 = [str(x) for x in label_V2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "Dapp = Dapp.astype(d)\n",
    "Dtest = Dtest.astype(d)\n",
    "Dapp_num = Dapp.select_dtypes(include=['float64']) ; Dapp_cat = Dapp.select_dtypes(include=['category'])\n",
    "Dtest_num = Dtest.select_dtypes(include=['float64']) ; Dtest_cat = Dtest.select_dtypes(include=['category'])\n",
    "Dtest_cat.loc[: , \"V9\"] = pd.Series(pd.Categorical(Dtest_cat.loc[: , \"V9\"], categories=[\"1\",\"2\",\"3\"]))\n",
    "Dtest_cat.loc[: , \"V2\"] = Dtest_cat.loc[: , \"V2\"].astype(\"str\")\n",
    "Dapp_cat.loc[: , \"V2\"] = Dapp_cat.loc[: , \"V2\"].astype(\"str\")\n",
    "Dtest_cat.loc[: , \"V2\"] = pd.Series(pd.Categorical(Dtest_cat.loc[: , \"V2\"], categories=label_V2))\n",
    "Dapp_cat.loc[: , \"V2\"] = pd.Series(pd.Categorical(Dapp_cat.loc[: , \"V2\"], categories=label_V2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(l):\n",
    "    return np.array([float(x) for x in l])\n",
    "\n",
    "imputed_training=mice(np.array(list(map(g , Dapp_num.values))))\n",
    "imputed_test = mice(np.array(list(map(g , Dtest_num.values))))\n",
    "\n",
    "Dapp_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputed_training))))).round(2)\n",
    "Dapp_num_imputed.columns = liste_numerical\n",
    "\n",
    "Dtest_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputed_test))))).round(2)\n",
    "Dtest_num_imputed.columns = liste_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Benco\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## On a généré quelques valeurs négatives, il est nécessaire d'effectuer de nouvelles imputations sur nos données\n",
    "Dapp_num_imputed[Dapp_num_imputed < 0] = np.nan\n",
    "Dtest_num_imputed[Dtest_num_imputed < 0] = np.nan\n",
    "\n",
    "distances_app = pdist(Dapp_num_imputed.values, metric='euclidean')\n",
    "dist_matrix_app = squareform(distances_app)\n",
    "matrice_distance_app = pd.DataFrame(list(map(np.ravel, (list(dist_matrix_app))))).round(2)\n",
    "\n",
    "distances_test = pdist(Dtest_num_imputed.values, metric='euclidean')\n",
    "dist_matrix_test = squareform(distances_test)\n",
    "matrice_distance_test = pd.DataFrame(list(map(np.ravel, (list(dist_matrix_test))))).round(2)\n",
    "#on ne peut pas se permettre de prendre des poids uniformes\n",
    "#en effet, il se peut que le 2e plus proche soit en réalité très loin du point par rapport au premier\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=15, weights=\"distance\")\n",
    "Dapp_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputer.fit_transform(Dapp_num_imputed)))))).round(2)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3, weights=\"distance\")\n",
    "Dtest_num_imputed = pd.DataFrame(list(map(np.ravel, (list(imputer.fit_transform(Dtest_num_imputed)))))).round(2)\n",
    "\n",
    "Dapp_num_imputed.columns = liste_numerical ; Dtest_num_imputed.columns = liste_numerical\n",
    "#le choix du nombre de voisins est difficile, on fait donc des choix arbitraires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V3': 0.19999999999999996,\n",
       " 'V4': 0.07999999999999996,\n",
       " 'V5': 0.19333333333333336,\n",
       " 'V15': 0.8233333333333334,\n",
       " 'V18': 0.09666666666666668,\n",
       " 'V19': 0.10999999999999999,\n",
       " 'V21': 0.6599999999999999}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{lab : 1-(len(Dtest_num[lab].dropna())/len(Dtest_num)) for lab in liste_numerical} \n",
    "{lab : 1-(len(Dapp_num[lab].dropna())/len(Dapp_num)) for lab in liste_numerical} \n",
    "#proportion de données manquantes pour les variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 251,
       "width": 376
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = Dapp_num.V21\n",
    "y = Dapp_num_imputed.V21\n",
    "#L'objectif est de comparer les distributions pour voir si l'on observe une certaine cohérence après imputation\n",
    "#on compare les distributions avant/après\n",
    "#on calcule aussi la proportion de données manquantes pour être sûr que la comparaison ait un sens.\n",
    "#il faut que le % de données manquantes ne soit ni trop faible ni trop élevé pour pouvoir comparer\n",
    "#on peut faire une \"évaluation\" visuelle de notre imputation sur cette variable choisie\n",
    "plt.hist([x, y], label=['Missing data', 'Imputed data'] , color = [\"plum\",\"peru\"])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n"
     ]
    }
   ],
   "source": [
    "#Dapp_cat = Dapp_cat.drop([\"V2\"] , axis = 1) ; Dtest_cat = Dtest_cat.drop([\"V2\"] , axis = 1)\n",
    "cat_cols = [Dapp_cat.columns.get_loc(col) for col in Dapp_cat.select_dtypes(['category']).columns.tolist()]\n",
    "\n",
    "imputer = MissForest(random_state = 100)\n",
    "Dapp_cat_imputed = imputer.fit_transform(Dapp_cat , cat_vars = cat_cols)\n",
    "Dapp_cat_imputed = pd.DataFrame(list(map(np.ravel, (list(Dapp_cat_imputed)))))\n",
    "Dapp_cat_imputed.columns = [x for x in liste_categorical] #if(x!=\"V2\")\n",
    "Dapp_cat_imputed = Dapp_cat_imputed.apply(lambda x : x.astype(int).astype(str).astype(\"category\") , axis = 1)\n",
    "Dapp_cat_imputed.loc[: , \"V2\"] = Dapp_cat_imputed.loc[: , \"V2\"].astype(\"str\")\n",
    "Dapp_cat_imputed.loc[: , \"V2\"] = pd.Series(pd.Categorical(Dapp_cat_imputed.loc[: , \"V2\"], categories=label_V2))\n",
    "\n",
    "\n",
    "Dtest_cat_imputed = imputer.transform(Dtest_cat)\n",
    "Dtest_cat_imputed = pd.DataFrame(list(map(np.ravel, (list(Dtest_cat_imputed)))))\n",
    "Dtest_cat_imputed.columns = [x for x in liste_categorical] #if(x!=\"V2\")\n",
    "Dtest_cat_imputed = Dtest_cat_imputed.apply(lambda x : x.astype(int).astype(str).astype(\"category\") , axis = 1)\n",
    "Dtest_cat_imputed.loc[: , \"V9\"] = pd.Series(pd.Categorical(Dtest_cat_imputed.loc[: , \"V9\"], categories=[\"1\",\"2\",\"3\"]))\n",
    "Dtest_cat_imputed.loc[: , \"V2\"] = Dtest_cat_imputed.loc[: , \"V2\"].astype(\"str\")\n",
    "Dtest_cat_imputed.loc[: , \"V2\"] = pd.Series(pd.Categorical(Dtest_cat_imputed.loc[: , \"V2\"], categories=label_V2))\n",
    "#une modalité de V9 n'est pas présente dans la variable V9 des données de test : il faut rajouter une catégorie\n",
    "#pour la variable V9 des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V0': 0.0033333333333332993,\n",
       " 'V1': 0.0,\n",
       " 'V6': 0.18666666666666665,\n",
       " 'V7': 0.22999999999999998,\n",
       " 'V8': 0.15666666666666662,\n",
       " 'V9': 0.10666666666666669,\n",
       " 'V10': 0.18333333333333335,\n",
       " 'V11': 0.1466666666666666,\n",
       " 'V12': 0.18666666666666665,\n",
       " 'V13': 0.3466666666666667,\n",
       " 'V14': 0.3533333333333334,\n",
       " 'V16': 0.33999999999999997,\n",
       " 'V17': 0.3933333333333333,\n",
       " 'V20': 0.55}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{lab : 1-(len(Dtest_cat[lab].dropna())/len(Dtest)) for lab in liste_categorical if(lab != \"V2\")} \n",
    "{lab : 1-(len(Dapp_cat[lab].dropna())/len(Dapp)) for lab in liste_categorical if(lab != \"V2\")}\n",
    "#les proportions de données manquantes pour chaque variable qualitative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236a0f4d108>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 356,
       "width": 544
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dapp_cat_imputed.V14.value_counts().sort_index().plot(kind = \"bar\")\n",
    "#en pratique, il est nécessaire de vérifier la distribution des variables avant\\après imputation\n",
    "#on trace donc des barplot pour avoir une idée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x236a0ed4808>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 356,
       "width": 544
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dapp_cat[\"V14\"].value_counts().sort_index().plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>528626</td>\n",
       "      <td>38.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.90</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>527950</td>\n",
       "      <td>37.6</td>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>535263</td>\n",
       "      <td>37.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>534523</td>\n",
       "      <td>37.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>528452</td>\n",
       "      <td>37.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>534783</td>\n",
       "      <td>38.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>528926</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>530670</td>\n",
       "      <td>37.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V0 V1      V2    V3    V4    V5 V6 V7 V8 V9  ... V13 V14   V15 V16 V17  \\\n",
       "0   2  1  528626  38.5  54.0  20.0  3  1  2  2  ...   2   2  5.90   4   2   \n",
       "1   2  1  527950  37.6  48.0  36.0  1  1  1  1  ...   1   1  4.94   3   5   \n",
       "2   1  1  535263  37.7  44.0  28.0  4  4  3  2  ...   1   1  2.35   3   5   \n",
       "3   1  1  534523  37.0  56.0  24.0  3  1  4  2  ...   1   1  1.60   4   5   \n",
       ".. .. ..     ...   ...   ...   ... .. .. .. ..  ...  ..  ..   ...  ..  ..   \n",
       "64  2  1  528452  37.8  42.0  40.0  1  1  1  1  ...   2   1  6.91   3   3   \n",
       "65  1  1  534783  38.0  60.0  12.0  1  1  2  1  ...   1   1  2.21   1   4   \n",
       "66  2  1  528926  38.0  42.0  12.0  3  1  3  1  ...   2   1  5.91   4   1   \n",
       "67  2  1  530670  37.6  88.0  36.0  3  1  1  1  ...   1   3  1.50   4   4   \n",
       "\n",
       "     V18   V19 V20    V21  V23  \n",
       "0   42.0   6.3   2   4.23    2  \n",
       "1   44.0   6.3   1   5.00    2  \n",
       "2   45.0  70.0   3   2.00    1  \n",
       "3   35.0  61.0   3   2.00    2  \n",
       "..   ...   ...  ..    ...  ...  \n",
       "64  36.0   6.2   2   2.77    2  \n",
       "65  44.0  65.0   3   2.00    1  \n",
       "66  37.0   5.8   2   2.64    2  \n",
       "67  44.0   6.0   2  10.08    1  \n",
       "\n",
       "[68 rows x 23 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dapp_imputed = pd.concat([Dapp_num_imputed.reset_index(drop=True), Dapp_cat_imputed], axis=1)\n",
    "Dapp_imputed.columns = [int(x[1:]) for x in Dapp_imputed.columns]\n",
    "Dapp_imputed = Dapp_imputed.sort_index(axis = 1)\n",
    "Dapp_imputed.columns = [\"V\"+str(x) for x in Dapp_imputed.columns]\n",
    "\n",
    "Dtest_imputed = pd.concat([Dtest_num_imputed.reset_index(drop=True), Dtest_cat_imputed], axis=1)\n",
    "Dtest_imputed.columns = [int(x[1:]) for x in Dtest_imputed.columns]\n",
    "Dtest_imputed = Dtest_imputed.sort_index(axis = 1)\n",
    "Dtest_imputed.columns = [\"V\"+str(x) for x in Dtest_imputed.columns]\n",
    "Dtest_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V15</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "      <th>V0_2</th>\n",
       "      <th>V1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>V14_3</th>\n",
       "      <th>V16_2</th>\n",
       "      <th>V16_3</th>\n",
       "      <th>V16_4</th>\n",
       "      <th>V17_2</th>\n",
       "      <th>V17_3</th>\n",
       "      <th>V17_4</th>\n",
       "      <th>V17_5</th>\n",
       "      <th>V20_2</th>\n",
       "      <th>V20_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.498439</td>\n",
       "      <td>-0.217177</td>\n",
       "      <td>-0.157651</td>\n",
       "      <td>0.558629</td>\n",
       "      <td>-0.129189</td>\n",
       "      <td>-0.616191</td>\n",
       "      <td>0.334439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.563263</td>\n",
       "      <td>0.574948</td>\n",
       "      <td>-0.652379</td>\n",
       "      <td>-1.620521</td>\n",
       "      <td>0.373636</td>\n",
       "      <td>2.340070</td>\n",
       "      <td>-0.696632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.194204</td>\n",
       "      <td>-1.153324</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>0.727474</td>\n",
       "      <td>-1.335970</td>\n",
       "      <td>-0.681800</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>3.311379</td>\n",
       "      <td>3.305444</td>\n",
       "      <td>0.226217</td>\n",
       "      <td>0.172506</td>\n",
       "      <td>-0.662504</td>\n",
       "      <td>1.633871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>-1.479091</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>-0.238106</td>\n",
       "      <td>-0.229754</td>\n",
       "      <td>-0.078198</td>\n",
       "      <td>0.221445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>-1.022738</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.033969</td>\n",
       "      <td>0.579735</td>\n",
       "      <td>1.379287</td>\n",
       "      <td>-0.677941</td>\n",
       "      <td>0.482744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>-2.543915</td>\n",
       "      <td>1.007016</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>-0.665494</td>\n",
       "      <td>0.373636</td>\n",
       "      <td>-0.708816</td>\n",
       "      <td>0.292066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>-1.479091</td>\n",
       "      <td>-1.153324</td>\n",
       "      <td>-0.652379</td>\n",
       "      <td>-1.404189</td>\n",
       "      <td>-1.034275</td>\n",
       "      <td>1.452420</td>\n",
       "      <td>-1.402845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V3        V4        V5       V15       V18       V19       V21  \\\n",
       "0    0.498439 -0.217177 -0.157651  0.558629 -0.129189 -0.616191  0.334439   \n",
       "1    1.563263  0.574948 -0.652379 -1.620521  0.373636  2.340070 -0.696632   \n",
       "2    0.194204 -1.153324 -0.405015  0.727474 -1.335970 -0.681800  0.164948   \n",
       "3    1.411145  3.311379  3.305444  0.226217  0.172506 -0.662504  1.633871   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "296 -1.479091 -0.001143 -0.405015 -0.238106 -0.229754 -0.078198  0.221445   \n",
       "297 -1.022738 -0.001143 -0.033969  0.579735  1.379287 -0.677941  0.482744   \n",
       "298 -2.543915  1.007016 -0.405015 -0.665494  0.373636 -0.708816  0.292066   \n",
       "299 -1.479091 -1.153324 -0.652379 -1.404189 -1.034275  1.452420 -1.402845   \n",
       "\n",
       "     V23  V0_2  V1_9  ...  V14_3  V16_2  V16_3  V16_4  V17_2  V17_3  V17_4  \\\n",
       "0      0     1     0  ...      0      0      1      0      0      0      0   \n",
       "1      0     0     0  ...      0      0      0      1      1      0      0   \n",
       "2      0     1     0  ...      0      0      0      0      0      0      0   \n",
       "3      0     0     1  ...      0      0      1      0      0      0      0   \n",
       "..   ...   ...   ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "296    0     1     0  ...      0      0      0      1      0      0      1   \n",
       "297    0     0     0  ...      0      0      1      0      0      0      0   \n",
       "298    0     0     0  ...      0      0      0      1      0      0      1   \n",
       "299    0     0     0  ...      0      0      0      1      0      0      0   \n",
       "\n",
       "     V17_5  V20_2  V20_3  \n",
       "0        1      0      1  \n",
       "1        0      1      0  \n",
       "2        0      0      0  \n",
       "3        1      0      1  \n",
       "..     ...    ...    ...  \n",
       "296      0      0      1  \n",
       "297      1      0      1  \n",
       "298      0      0      1  \n",
       "299      0      0      0  \n",
       "\n",
       "[300 rows x 391 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dapp_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dtest_imputed.to_pickle(\"Dtest_imputed.pkl\")\n",
    "#Dapp_imputed.to_pickle(\"Dapp_imputed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dapp_imputed = pd.read_pickle(\"Dapp_imputed.pkl\")\n",
    "#Dtest_imputed = pd.read_pickle(\"Dtest_imputed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_cat_bis = [x for x in liste_categorical if(x not in [\"V23\"] )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V15</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "      <th>V0_2</th>\n",
       "      <th>V1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>V14_3</th>\n",
       "      <th>V16_2</th>\n",
       "      <th>V16_3</th>\n",
       "      <th>V16_4</th>\n",
       "      <th>V17_2</th>\n",
       "      <th>V17_3</th>\n",
       "      <th>V17_4</th>\n",
       "      <th>V17_5</th>\n",
       "      <th>V20_2</th>\n",
       "      <th>V20_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.498439</td>\n",
       "      <td>-0.649245</td>\n",
       "      <td>-0.652379</td>\n",
       "      <td>0.701092</td>\n",
       "      <td>-0.430885</td>\n",
       "      <td>-0.697238</td>\n",
       "      <td>0.878223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.870620</td>\n",
       "      <td>-0.865279</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>0.194558</td>\n",
       "      <td>-0.229754</td>\n",
       "      <td>-0.697238</td>\n",
       "      <td>1.422007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.718503</td>\n",
       "      <td>-1.009301</td>\n",
       "      <td>-0.157651</td>\n",
       "      <td>-1.172028</td>\n",
       "      <td>-0.129189</td>\n",
       "      <td>1.761168</td>\n",
       "      <td>-0.696632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.783327</td>\n",
       "      <td>-0.577233</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>-1.567757</td>\n",
       "      <td>-1.134840</td>\n",
       "      <td>1.413826</td>\n",
       "      <td>-0.696632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>-0.566385</td>\n",
       "      <td>-1.081313</td>\n",
       "      <td>0.584441</td>\n",
       "      <td>1.234008</td>\n",
       "      <td>-1.034275</td>\n",
       "      <td>-0.701097</td>\n",
       "      <td>-0.152848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>-0.262150</td>\n",
       "      <td>-0.433211</td>\n",
       "      <td>-1.147107</td>\n",
       "      <td>-1.245897</td>\n",
       "      <td>-0.229754</td>\n",
       "      <td>1.568200</td>\n",
       "      <td>-0.696632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>-0.262150</td>\n",
       "      <td>-1.081313</td>\n",
       "      <td>-1.147107</td>\n",
       "      <td>0.706369</td>\n",
       "      <td>-0.933710</td>\n",
       "      <td>-0.716535</td>\n",
       "      <td>-0.244656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>-0.870620</td>\n",
       "      <td>0.574948</td>\n",
       "      <td>0.337077</td>\n",
       "      <td>-1.620521</td>\n",
       "      <td>-0.229754</td>\n",
       "      <td>-0.708816</td>\n",
       "      <td>5.009569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V3        V4        V5       V15       V18       V19       V21  V23  \\\n",
       "0   0.498439 -0.649245 -0.652379  0.701092 -0.430885 -0.697238  0.878223    0   \n",
       "1  -0.870620 -0.865279  0.337077  0.194558 -0.229754 -0.697238  1.422007    0   \n",
       "2  -0.718503 -1.009301 -0.157651 -1.172028 -0.129189  1.761168 -0.696632    1   \n",
       "3  -1.783327 -0.577233 -0.405015 -1.567757 -1.134840  1.413826 -0.696632    0   \n",
       "..       ...       ...       ...       ...       ...       ...       ...  ...   \n",
       "64 -0.566385 -1.081313  0.584441  1.234008 -1.034275 -0.701097 -0.152848    0   \n",
       "65 -0.262150 -0.433211 -1.147107 -1.245897 -0.229754  1.568200 -0.696632    1   \n",
       "66 -0.262150 -1.081313 -1.147107  0.706369 -0.933710 -0.716535 -0.244656    0   \n",
       "67 -0.870620  0.574948  0.337077 -1.620521 -0.229754 -0.708816  5.009569    1   \n",
       "\n",
       "    V0_2  V1_9  ...  V14_3  V16_2  V16_3  V16_4  V17_2  V17_3  V17_4  V17_5  \\\n",
       "0      1     0  ...      0      0      0      1      1      0      0      0   \n",
       "1      1     0  ...      0      0      1      0      0      0      0      1   \n",
       "2      0     0  ...      0      0      1      0      0      0      0      1   \n",
       "3      0     0  ...      0      0      0      1      0      0      0      1   \n",
       "..   ...   ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "64     1     0  ...      0      0      1      0      0      1      0      0   \n",
       "65     0     0  ...      0      0      0      0      0      0      1      0   \n",
       "66     1     0  ...      0      0      0      1      0      0      0      0   \n",
       "67     1     0  ...      1      0      0      1      0      0      1      0   \n",
       "\n",
       "    V20_2  V20_3  \n",
       "0       1      0  \n",
       "1       0      0  \n",
       "2       0      1  \n",
       "3       0      1  \n",
       "..    ...    ...  \n",
       "64      1      0  \n",
       "65      0      1  \n",
       "66      1      0  \n",
       "67      1      0  \n",
       "\n",
       "[68 rows x 391 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Dapp_imputed[liste_numerical] = scaler.fit_transform(Dapp_imputed[liste_numerical])\n",
    "Dapp_imputed[\"V23\"] = pd.Series([1 if(x==\"1\") else 0 for x in Dapp_imputed[\"V23\"]])\n",
    "Dapp_imputed = Dapp_imputed.astype({\"V23\" : \"int32\"})\n",
    "Dapp_imputed = pd.get_dummies(Dapp_imputed , columns = liste_cat_bis , drop_first = True)\n",
    "\n",
    "Dtest_imputed[liste_numerical] = scaler.transform(Dtest_imputed[liste_numerical])\n",
    "Dtest_imputed[\"V23\"] = pd.Series([1 if(x==\"1\") else 0 for x in Dtest_imputed[\"V23\"]])\n",
    "Dtest_imputed = Dtest_imputed.astype({\"V23\" : \"int32\"})\n",
    "Dtest_imputed = pd.get_dummies(Dtest_imputed , columns = liste_cat_bis , drop_first = True)\n",
    "\n",
    "Dapp_imputed\n",
    "Dtest_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V15</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V21</th>\n",
       "      <th>V23</th>\n",
       "      <th>V0_2</th>\n",
       "      <th>V1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>V14_3</th>\n",
       "      <th>V16_2</th>\n",
       "      <th>V16_3</th>\n",
       "      <th>V16_4</th>\n",
       "      <th>V17_2</th>\n",
       "      <th>V17_3</th>\n",
       "      <th>V17_4</th>\n",
       "      <th>V17_5</th>\n",
       "      <th>V20_2</th>\n",
       "      <th>V20_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.498439</td>\n",
       "      <td>-0.217177</td>\n",
       "      <td>-0.157651</td>\n",
       "      <td>0.558629</td>\n",
       "      <td>-0.129189</td>\n",
       "      <td>-0.616191</td>\n",
       "      <td>0.334439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.563263</td>\n",
       "      <td>0.574948</td>\n",
       "      <td>-0.652379</td>\n",
       "      <td>-1.620521</td>\n",
       "      <td>0.373636</td>\n",
       "      <td>2.340070</td>\n",
       "      <td>-0.696632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.194204</td>\n",
       "      <td>-1.153324</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>0.727474</td>\n",
       "      <td>-1.335970</td>\n",
       "      <td>-0.681800</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>3.311379</td>\n",
       "      <td>3.305444</td>\n",
       "      <td>0.226217</td>\n",
       "      <td>0.172506</td>\n",
       "      <td>-0.662504</td>\n",
       "      <td>1.633871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>-1.479091</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>-0.238106</td>\n",
       "      <td>-0.229754</td>\n",
       "      <td>-0.078198</td>\n",
       "      <td>0.221445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>-1.022738</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.033969</td>\n",
       "      <td>0.579735</td>\n",
       "      <td>1.379287</td>\n",
       "      <td>-0.677941</td>\n",
       "      <td>0.482744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>-2.543915</td>\n",
       "      <td>1.007016</td>\n",
       "      <td>-0.405015</td>\n",
       "      <td>-0.665494</td>\n",
       "      <td>0.373636</td>\n",
       "      <td>-0.708816</td>\n",
       "      <td>0.292066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>-1.479091</td>\n",
       "      <td>-1.153324</td>\n",
       "      <td>-0.652379</td>\n",
       "      <td>-1.404189</td>\n",
       "      <td>-1.034275</td>\n",
       "      <td>1.452420</td>\n",
       "      <td>-1.402845</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V3        V4        V5       V15       V18       V19       V21  \\\n",
       "0    0.498439 -0.217177 -0.157651  0.558629 -0.129189 -0.616191  0.334439   \n",
       "1    1.563263  0.574948 -0.652379 -1.620521  0.373636  2.340070 -0.696632   \n",
       "2    0.194204 -1.153324 -0.405015  0.727474 -1.335970 -0.681800  0.164948   \n",
       "3    1.411145  3.311379  3.305444  0.226217  0.172506 -0.662504  1.633871   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "296 -1.479091 -0.001143 -0.405015 -0.238106 -0.229754 -0.078198  0.221445   \n",
       "297 -1.022738 -0.001143 -0.033969  0.579735  1.379287 -0.677941  0.482744   \n",
       "298 -2.543915  1.007016 -0.405015 -0.665494  0.373636 -0.708816  0.292066   \n",
       "299 -1.479091 -1.153324 -0.652379 -1.404189 -1.034275  1.452420 -1.402845   \n",
       "\n",
       "     V23  V0_2  V1_9  ...  V14_3  V16_2  V16_3  V16_4  V17_2  V17_3  V17_4  \\\n",
       "0      0     1     0  ...      0      0      1      0      0      0      0   \n",
       "1      0     0     0  ...      0      0      0      1      1      0      0   \n",
       "2      0     1     0  ...      0      0      0      0      0      0      0   \n",
       "3      0     0     1  ...      0      0      1      0      0      0      0   \n",
       "..   ...   ...   ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "296    0     1     0  ...      0      0      0      1      0      0      1   \n",
       "297    0     0     0  ...      0      0      1      0      0      0      0   \n",
       "298    0     0     0  ...      0      0      0      1      0      0      1   \n",
       "299    0     0     0  ...      0      0      0      1      0      0      0   \n",
       "\n",
       "     V17_5  V20_2  V20_3  \n",
       "0        1      0      1  \n",
       "1        0      1      0  \n",
       "2        0      0      0  \n",
       "3        1      0      1  \n",
       "..     ...    ...    ...  \n",
       "296      0      0      1  \n",
       "297      1      0      1  \n",
       "298      0      0      1  \n",
       "299      0      0      0  \n",
       "\n",
       "[300 rows x 391 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dapp_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = Dapp_imputed.drop([\"V23\"] , axis = 1) ; Y_train = Dapp_imputed[\"V23\"]\n",
    "X_test = Dtest_imputed.drop([\"V23\"] , axis = 1) ; Y_test = Dtest_imputed[\"V23\"]\n",
    "#Voici nos jeux de données d'entrainement ainsi que de tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(np.dot(np.transpose(X_train) , X_train)) #la matrice de design n'est pas de rang plein, rien ne nous garantit que\n",
    "#que l'on atteindra un minimum global en faisant une régression logistique\n",
    "#on décide de pénaliser celle-ci avec une pénalité de type ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty = \"none\", solver = \"lbfgs\" , max_iter = 5000 , tol = 1e-6)\n",
    "logreg.fit(X_train , Y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_fit = logreg.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def param_selection_log(X, y,Cs):\n",
    "    logreg = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\" , max_iter = 5000 , tol = 1e-6)\n",
    "    parameters = {'C':Cs}\n",
    "    clf = GridSearchCV(logreg, parameters, cv = KFold(n_splits = 3))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.best_params_\n",
    "\n",
    "C_log = param_selection_log(X_train, Y_train , [.001 , 0.01 , 0.1 , 1 , 10 , 100])[\"C\"]\n",
    "\n",
    "logreg = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\" , max_iter = 5000 , tol = 1e-6 , C = C_log)\n",
    "logreg.fit(X_train , Y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_fit = logreg.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test) #1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train) #on dipose d'une erreur d'apprentissage nulle\n",
    "#cela laisse présager du sur-apprentissage --> dès lors, on peut remettre en doute notre performance\n",
    "#de plus, on constate qu'il existe une séparation linéaire des données\n",
    "#nous allons donc utiliser un autre classifieur linéaire : SVML\n",
    "#une SVM à noyaux est inutile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.Series([-1 if(y==0) else 1 for y in Y_train])\n",
    "Y_test = pd.Series([-1 if(y==0) else 1 for y in Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svc_param_selection_lin(X, y,Cs):\n",
    "    parameters = {'kernel':['linear'], 'C':Cs}\n",
    "    svc = svm.SVC(gamma = 1 , coef0 = 0)\n",
    "    clf = GridSearchCV(svc, parameters , return_train_score = True , cv = KFold(n_splits = 3))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    return clf.best_params_\n",
    "##on effectue une VC 3-fold car moins coûteuse\n",
    "C_lin = svc_param_selection_lin(X_train, Y_train , [.001 , 0.01 , 0.1 , 0.14])[\"C\"]\n",
    "\n",
    "svm_lin = LinearSVC(C = C_lin , max_iter = 10000)\n",
    "svm_lin.fit(X_train , Y_train)\n",
    "y_pred = svm_lin.predict(X_test)\n",
    "y_fit = svm_lin.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n",
    "#même performance/problème que la régression logistique\n",
    "#tout laisse penser que l'on est vite confronté à un problème de sur-apprentissage\n",
    "#lorsque l'on essaye d'ajuster le paramètre C à l'aide d'une validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9433333333333334"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_m(liste): #renvoie le m minimisant l'erreur OOB\n",
    "    l = []\n",
    "    for m in liste:\n",
    "        clf = RandomForestClassifier(random_state = 0,\n",
    "                             n_estimators = 100 , max_features = m , min_samples_split = 2,\n",
    "                            oob_score = True)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        l.append((m , clf.oob_score_))\n",
    "    return min(l , key = lambda x : x[1])[0]\n",
    "\n",
    "m = oob_m(range(1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8088235294117647"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state = 0,\n",
    "                             n_estimators = 100 , max_features = m , min_samples_split = 2,\n",
    "                            oob_score = True)\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_fit = clf.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n",
    "#accuracy_score(y_fit, Y_train)\n",
    "\n",
    "#moins performante que les précédentes mais l'erreur d'ajustement est nulle aussi --> hypothèse de sur-ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_CV(ms):\n",
    "    rfc = RandomForestClassifier(random_state = 0, min_samples_split = 2,\n",
    "                            oob_score = True , n_estimators = 100)\n",
    "    param_grid = {'max_features': ms}\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= KFold(n_splits = 3))\n",
    "    CV_rfc.fit(X_train, Y_train)\n",
    "    return CV_rfc.best_params_[\"max_features\"]\n",
    "#on décide de faire une 3-fold car la LOO est coûteuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = list(range(1,6))\n",
    "m = rfc_CV(ms)\n",
    "rfc = RandomForestClassifier(random_state = 0,\n",
    "                             n_estimators = 100 , max_features = m , min_samples_split = 2,\n",
    "                            oob_score = True)\n",
    "rfc.fit(X_train, Y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_fit = rfc.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n",
    "#idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_CV(ks):\n",
    "    neigh = KNeighborsClassifier()\n",
    "    param_grid = {'n_neighbors': ks}\n",
    "    CV_knn = GridSearchCV(estimator=neigh, param_grid=param_grid, cv= KFold(n_splits = 3))\n",
    "    CV_knn.fit(X_train, Y_train)\n",
    "    return CV_knn.best_params_[\"n_neighbors\"]\n",
    "k = knn_CV(list(range(1,30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "neigh.fit(X_train, Y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "y_fit = neigh.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)\n",
    "#ici le phénomène s'inverse, par VC, on obtient k tel que l'erreur d'ajustement est élevé -- > sous-apprentissage\n",
    "#le biais de l'algorithme est élevé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_CV(ns ,ls):\n",
    "    ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1) , random_state=0)\n",
    "    param_grid = {'n_estimators': ns , \"learning_rate\" : ls}\n",
    "    CV_ada = GridSearchCV(estimator=ada, param_grid=param_grid, cv= KFold(n_splits = 3))\n",
    "    CV_ada.fit(X_train, Y_train)\n",
    "    return CV_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8382352941176471"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = ada_CV(list(range(10,19)) , np.linspace(0.1 , 0.2 , 10))\n",
    "ada = AdaBoostClassifier(n_estimators = params[\"n_estimators\"] ,\n",
    "                         learning_rate = params[\"learning_rate\"],\n",
    "                         random_state=0)\n",
    "ada.fit(X_train, Y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "y_fit = ada.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.14444444444444446, 'n_estimators': 18}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466666666666667"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accuracy_score(y_fit, Y_train))\n",
    "#ce modèle semble ne pas souffrir de sur-apprentissage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree_grid_search(X,y,depth):\n",
    "    param_grid = {'max_depth': depth}\n",
    "    dtree_model=DecisionTreeClassifier(random_state = 0)\n",
    "    dtree_gscv = GridSearchCV(dtree_model, param_grid, cv= KFold(n_splits = 3))\n",
    "    dtree_gscv.fit(X, y)\n",
    "    return dtree_gscv.best_params_\n",
    "\n",
    "P = dtree_grid_search(X_train,Y_train,list(range(3,30)))[\"max_depth\"]\n",
    "\n",
    "arb = DecisionTreeClassifier(random_state=0 , max_depth = P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8382352941176471"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arb.fit(X_train, Y_train)\n",
    "y_pred = arb.predict(X_test)\n",
    "y_fit = arb.predict(X_train)\n",
    "accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_fit, Y_train) #cet algorithme souffre aussi du sur-apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En conclusion, on décide de supprimer la variable ID pour éviter ces problèmes de sur-apprentissage lors de la\n",
    "#calibration des paramètres\n",
    "#En la supprimant, les procédures de validation croisée nous permettront de déterminer des paramètres qui nous feront\n",
    "#éviter le sur-apprentissage et par la même occasion le sous-apprentissage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
